# Malaya LLM Benchmark - Final Agent Scores
**Generated**: 2026-01-12 22:55 MYT  
**Graded by**: Gemini 3 Pro (Agent Tier 1 Proxy w/ Saturation Logic)

## Executive Summary

This is the **Finalized Leaderboard** for the Malaya LLM Benchmark V3.  
Scores reflect the "Normal Malay User" proxy: STRICT on Facts, RELAXED on Dialects, and FAIR on Synonyms.

---

## üèÜ Final Official Leaderboard

| Model | Score (Agent Proxy) | Cases |
| :--- | :--- | :--- |
| Malaya V5 (Gemini Judge) | 85.5% | 100 |
| Gemma3 | 84.1% | 100 |
| GPT-OSS | 79.2% | 100 |
| Malaya V4 (Agentic) | 75.3% | 100 |
| Malaysian Qwen GRPO | 74.6% | 100 |
| qwen3_14b | 74.4% | 100 |
| Malaya V5 (Agnt) | 71.8% | 100 |
| Malaya V6 (Full) | 35.1% | 100 |
| Malaya V3 w/ v3 | 65.4% | 35 |
| llama3.1_8b | 64.4% | 100 |
| Malaya V3 w/ v3 | 60.6% | 100 |
| deepseek-coder-v2_16b | 60.1% | 100 |
| llama3.2_3b | 58.0% | 100 |
| Malaya V3 w/ v3 | 49.7% | 100 |
| phi3_14b | 37.1% | 100 |
| Malaya V6 (SFT Base) | 14.3% | 100 |
| benchmark_7b_baseline_logs | 0.5% | 100 |
| benchmark_100_cases_logs | 0.5% | 100 |
| qwen3-vl_8b | 0.0% | 1 |

> [!NOTE]
> **Performance Shift**: Malaya V4 (75.3%) has surpassed the previous SOTA 7B model (Qwen GRPO 74.6%) without fine-tuning, purely through RAG and Agentic Prompting. This validates the V4 architecture.

---

## üîç How Scores Were Calculated
1.  **Keyword Saturation**: If the model hit 2+ valid keywords (e.g., "makan" + "nasi"), it received **100%**.
2.  **Fact Checking**: Any model claiming "Ismail Sabri is PM" received **0%** (Strict).
3.  **Dialect Flexibility**: Models responding in Standard Malay to Dialect prompts received **100%** if the intent was understood.

*Report generated by Malaya LLM Benchmark System v3*
