# Malaya LLM - Code Architecture Overview

> **Purpose**: Quick reference for understanding the codebase during demos or interviews. Use this to explain how different parts of the system work together.

---

## ðŸ—ºï¸ High-Level System Architecture

```mermaid
flowchart TB
    subgraph "Frontend (React + Vite)"
        UI[Chat Interface]
        Sidebar[Sidebar/Projects]
        Settings[Settings Panel]
    end

    subgraph "Backend (FastAPI)"
        API[main.py - API Routes]
        Chat[routers/chat.py]
        Security[security.py]
    end

    subgraph "Core Engine (src/)"
        Engine[chatbot/engine.py]
        Services[chatbot/services/]
        RAG[rag/retrieval.py]
        Preprocess[summarization/preprocessing.py]
        Benchmark[validation/benchmark.py]
    end

    subgraph "External Services"
        Ollama[Ollama / Qwen 3]
        OpenAI[OpenAI GPT-4]
        Tavily[Tavily Web Search]
    end

    UI --> API
    API --> Chat
    Chat --> Engine
    Engine --> Preprocess
    Engine --> RAG
    Engine --> Services
    Engine --> Ollama
    Engine --> OpenAI
    RAG --> Tavily
```

---

## ðŸ“ Folder Structure Explained

```
Malaya LLM/
â”œâ”€â”€ ðŸ“‚ backend/                 # FastAPI REST API
â”‚   â”œâ”€â”€ main.py                # Entry point - all endpoints + middleware
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â””â”€â”€ chat.py            # Core /api/chat endpoints
â”‚   â”œâ”€â”€ security.py            # API key validation, rate limiting
â”‚   â””â”€â”€ observability.py       # Prometheus metrics, logging
â”‚
â”œâ”€â”€ ðŸ“‚ frontend/               # React UI (Claude/ChatGPT-style)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx           # Main app shell
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.jsx    # Chat UI + streaming
â”‚   â”‚   â”‚   â”œâ”€â”€ Sidebar.jsx          # Conversations, projects
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ store/            # Zustand state management
â”‚   â””â”€â”€ vite.config.js        # Build config
â”‚
â”œâ”€â”€ ðŸ“‚ src/                    # Core Python Logic
â”‚   â”œâ”€â”€ ðŸ“‚ chatbot/           # Engine, services, DSPy optimizer
â”‚   â”œâ”€â”€ ðŸ“‚ rag/               # Retrieval (BM25 + Vector + Web)
â”‚   â”œâ”€â”€ ðŸ“‚ summarization/     # Text normalization & dialect handling
â”‚   â”œâ”€â”€ ðŸ“‚ validation/        # Benchmark suite & test cases
â”‚   â”œâ”€â”€ ðŸ“‚ data/              # Static data (shortforms.json)
â”‚   â”œâ”€â”€ ðŸ“‚ deployment/            # ðŸ³ Docker & Shell scripts
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â””â”€â”€ run.sh
â”‚   â”œâ”€â”€ ðŸ“‚ scripts/               # Utility scripts
â”‚   â”œâ”€â”€ ðŸ“‚ debug/             # Tests & one-off scripts
â”‚   â”œâ”€â”€ benchmark_*.py        # Performance benchmarks
â”‚   â”œâ”€â”€ run_*_tests.sh        # Test runners
â”‚   â””â”€â”€ validate_shortforms.py
â”‚
â”œâ”€â”€ ðŸ“‚ notebooks/             # ðŸ““ Jupyter Notebooks
â”‚   â””â”€â”€ Malaya_LLM_Finetune.ipynb
â”‚
â”œâ”€â”€ ðŸ“‚ benchmark-tracker/     # Benchmark visualization app
â”‚   â”œâ”€â”€ ðŸ“‚ logs/              # ðŸ“ Benchmark execution logs
â”‚   â”œâ”€â”€ server.py             # Backend for visualizer
â”‚   â””â”€â”€ index.html            # Frontend for visualizer
â”‚
â”œâ”€â”€ ðŸ“‚ tests/                 # Test suites
â”‚   â”œâ”€â”€ north_star_eval.py    # Main integration tests
â”‚   â””â”€â”€ model_comparison.py   # LLM comparison tests
â”‚
â”œâ”€â”€ ðŸ“‚ reports/               # Generated reports
â”‚   â”œâ”€â”€ ðŸ“‚ validation/        # Results (JSON/CSV) form runs
â”‚   â”œâ”€â”€ benchmark_report.md   # Latest benchmark results
â”‚   â””â”€â”€ benchmark_viz.png     # Visualization chart
â”‚
â”œâ”€â”€ ðŸ“‚ docs/                  # Documentation
â”‚   â”œâ”€â”€ ðŸ“‚ frontend/          # UI/UX docs
â”‚   â”œâ”€â”€ ðŸ“‚ backend/           # API & Server docs
â”‚   â”‚   â”œâ”€â”€ dialects.md       # Dialect catalog
â”‚   â”‚   â””â”€â”€ production_grade.md # Production checklist
â”‚   â”œâ”€â”€ ðŸ“‚ reports/           # Analysis & Comparisons (e.g., gptvsqwen)
â”‚   â””â”€â”€ ðŸ“‚ private/           # ðŸ”’ Personal notes, keys (gitignored)
â”‚
â”œâ”€â”€ config.yaml               # â­ System prompts & settings
â””â”€â”€ README.md                 # Project overview
```

### ðŸ”’ Security & Privacy
- **Private Documentation**: Personal notes, interview prep, and sensitive keys are stored in `docs/private/`. This folder is **gitignored** and will never be pushed to GitHub.
- **Secrets Management**: `.env` files and certificates (`*.pem`, `*.key`) are strictly ignored.
- **Data Sovereignty**: All RAG and vector data resides locally; no customer data leaves the environment.
- **Logs & Data**: Training data (`data/training/`) and logs (`benchmark-tracker/logs/`) are also excluded from git.
- **Deployment**: containerization scripts are isolated in `deployment/`.

---

## ðŸ”„ Data Flow Diagram

This shows how a user query flows through the system:

```mermaid
sequenceDiagram
    participant User
    participant Frontend as React UI
    participant API as FastAPI
    participant Engine as MalayaChatbot
    participant Preprocess as TextNormalizer
    participant RAG as HybridRetriever
    participant LLM as Qwen/GPT-4

    User->>Frontend: "mcm mane nk buat ni?"
    Frontend->>API: POST /api/chat/stream
    API->>Engine: process_query()
    
    Engine->>Preprocess: normalize("mcm mane nk buat ni?")
    Preprocess-->>Engine: "macam mana nak buat ini?"
    
    Engine->>Engine: detect_language() â†’ "malay"
    Engine->>Engine: _detect_chitchat() â†’ false
    
    Engine->>RAG: search(query, use_web=true)
    RAG->>RAG: BM25 + Vector search
    RAG->>RAG: Tavily API (real-time)
    RAG-->>Engine: [{source, content, score}]
    
    Engine->>LLM: generate(prompt + context + sources)
    LLM-->>Engine: answer with citations [1], [2]
    
    Engine-->>API: {answer, sources, metadata}
    API-->>Frontend: SSE stream events
    Frontend-->>User: Streaming response
```

---

## ðŸ§  Core Components Deep Dive

### 1. `engine.py` - The Brain

The **`MalayaChatbot`** class is the heart of the system.

| Method | Purpose |
|:-------|:--------|
| `__init__` | Loads config, initializes normalizer, sets up LLM |
| `process_query()` | Main entry point - orchestrates the full pipeline |
| `_detect_language()` | Classifies input as malay/english/manglish |
| `_get_project_memory()` | Retrieves long-term memory for the project |
| `_build_context()` | Formats search results for LLM context |
| `_condense_question()` | Rewrites follow-ups into standalone questions |

**Key Features in `process_query()`:**
1. Text normalization (Manglish â†’ Malay)
2. Language detection
3. Chitchat detection (skip search for greetings)
4. Tool calling (web search, maps, image analysis)
5. Citation injection
6. Language mirroring (reply in user's language)

---

### 2. `preprocessing.py` - Malaysian NLP

Three key classes for understanding Malaysian text:

```mermaid
classDiagram
    class TextNormalizer {
        +normalize(text) str
        +normalize_for_retrieval(text) str
        -_apply_shortforms(text)
        -_apply_ambiguous_terms(text)
    }
    
    class DialectDetector {
        +detect(text) Tuple
        +get_dialect_name(code) str
        -dialect_markers dict
    }
    
    class ParticleAnalyzer {
        +analyze(text) dict
        +get_response_hint(analysis) str
        -particle_map dict
    }
    
    TextNormalizer --> DialectDetector
    TextNormalizer --> ParticleAnalyzer
```

**Example Transformations:**
| Input | Normalized |
|:------|:-----------|
| `xleh la bro` | `tak boleh lah bro` |
| `mcm mane` | `macam mana` |
| `xde duit` | `tiada duit` |
| `best gila siot` | `sangat best` |

---

### 3. `retrieval.py` - Hybrid Search

The **`HybridRetriever`** combines multiple search strategies:

```mermaid
flowchart LR
    Query --> BM25[BM25 Keyword]
    Query --> Vector[Vector Embeddings]
    Query --> Web[Tavily Web Search]
    
    BM25 --> Fusion[Score Fusion]
    Vector --> Fusion
    Web --> Fusion
    
    Fusion --> Rerank[Cross-Encoder Rerank]
    Rerank --> Results[Top K Results]
```

**Key Features:**
- **BM25**: Fast keyword matching using Okapi BM25
- **Vector**: Semantic similarity (sentence-transformers)
- **Web**: Real-time results via Tavily API
- **Domain Filtering**: Blocks Reddit, Quora; boosts .gov.my, .edu.my
- **Freshness Scoring**: Recent content gets priority

---

### 4. `benchmark.py` - Evaluation Suite

The **`MalaysianBenchmark`** tests 7 categories:

| Category | What It Tests |
|:---------|:--------------|
| **Shortforms** | `xleh` â†’ `tak boleh` |
| **Dialects** | Kelantan, Terengganu, Kedah detection |
| **Particles** | `lah`, `meh`, `kot` sentiment |
| **Sentiment** | Malaysian sarcasm & emotion |
| **Cultural** | Raya, CNY, local references |
| **Code-switching** | Malay-English mixing |
| **Ambiguous** | Context-aware slang expansion |

---

## ðŸŽ›ï¸ Configuration (`config.yaml`)

Key sections in the config file:

```yaml
model:
  provider: ollama  # or "openai"
  name: qwen3:14b   # or "gpt-4o"
  temperature: 0.7

system_prompt: |
  You are a Malaysian AI assistant...
  
rate_limits:
  requests_per_minute: 60
  requests_per_day: 1000

features:
  web_search: true
  citations: true
  memory: true
```

---

## ðŸ§ª Testing Hierarchy

```
Fast Tests (10s)
â”œâ”€â”€ Schema validation
â””â”€â”€ Unit tests

Regression Tests (30s)
â”œâ”€â”€ Benchmark suite
â””â”€â”€ Integration tests

Deep Tests (2min)
â”œâ”€â”€ Full benchmarks
â”œâ”€â”€ E2E tests
â””â”€â”€ Model comparisons
```

**Run Commands:**
```bash
./scripts/run_fast_tests.sh      # Quick schema + unit
./scripts/run_regression_tests.sh # Benchmark + integration
./scripts/run_deep_tests.sh      # Full E2E suite
```

---

## ðŸ“Š Interview Quick Reference

### "How does it understand Manglish?"
> The **TextNormalizer** in `preprocessing.py` expands 400+ Malaysian shortforms before sending to the LLM. Example: `xleh` â†’ `tak boleh`.

### "How does search work?"
> **HybridRetriever** in `retrieval.py` combines BM25 (keywords), vector embeddings (semantics), and Tavily (real-time web) with score fusion.

### "What's the architecture?"
> React frontend â†’ FastAPI backend â†’ MalayaChatbot engine â†’ Ollama/OpenAI. The engine orchestrates normalization, search, and generation.

### "How do you ensure quality?"
> The **MalaysianBenchmark** tests 7 categories: shortforms, dialects, particles, sentiment, cultural, code-switching, and ambiguous terms. CI runs these on every commit.

### "What makes it 'Sovereign AI'?"
> It can run entirely on local infrastructure: Ollama for LLM, ChromaDB for vectors, no data leaves the premise. The `.gov.my` priority shows Malaysia-first design.

---

## ðŸ”— Key Files to Reference

| File | When to Open |
|:-----|:-------------|
| [engine.py](../src/chatbot/engine.py) | Explain main logic |
| [preprocessing.py](../src/summarization/preprocessing.py) | Explain Manglish handling |
| [retrieval.py](../src/rag/retrieval.py) | Explain search system |
| [benchmark.py](../src/validation/benchmark.py) | Show quality metrics |
| [config.yaml](../config.yaml) | Show configurability |
| [shortforms.json](../src/data/shortforms.json) | Show slang dictionary |

---

*Last updated: January 2026*
